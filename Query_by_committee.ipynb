{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, BatchNormalization, Activation, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils import plot_model\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('1-100.xlsx',encoding='utf-8')\n",
    "df_review_for_vocab = pd.read_csv('Tagged_Data_Values.csv',encoding='utf-8')\n",
    "df_review_for_vocab = df_review_for_vocab[:5000]\n",
    "df_review_for_vocab = df_review_for_vocab.dropna()\n",
    "maxlen = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = text.Tokenizer(num_words=200000)\n",
    "tok.fit_on_texts(df_review_for_vocab['review_body'].tolist())\n",
    "x = tok.texts_to_sequences(df['review_body'])\n",
    "x = sequence.pad_sequences(x, maxlen=maxlen)\n",
    "y = df['tag']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "word_index = tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "    except:\n",
    "        pass\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.7373 - acc: 0.4444 - val_loss: 0.6847 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.6799 - acc: 0.5556 - val_loss: 0.6595 - val_acc: 0.6250\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.6696 - acc: 0.5972 - val_loss: 0.6371 - val_acc: 0.7500\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.6446 - acc: 0.6389 - val_loss: 0.6154 - val_acc: 0.8750\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5929 - acc: 0.7222 - val_loss: 0.5927 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5875 - acc: 0.6944 - val_loss: 0.5698 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5958 - acc: 0.6944 - val_loss: 0.5467 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5547 - acc: 0.7083 - val_loss: 0.5229 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5332 - acc: 0.7917 - val_loss: 0.4985 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5068 - acc: 0.7639 - val_loss: 0.4739 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.5027 - acc: 0.7917 - val_loss: 0.4496 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4938 - acc: 0.7639 - val_loss: 0.4266 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4662 - acc: 0.8056 - val_loss: 0.4052 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4768 - acc: 0.7917 - val_loss: 0.3843 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4647 - acc: 0.7917 - val_loss: 0.3634 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4667 - acc: 0.7917 - val_loss: 0.3449 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4505 - acc: 0.7778 - val_loss: 0.3289 - val_acc: 0.8750\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4047 - acc: 0.8472 - val_loss: 0.3151 - val_acc: 0.8750\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4134 - acc: 0.8611 - val_loss: 0.2985 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.4028 - acc: 0.8056 - val_loss: 0.2837 - val_acc: 1.0000\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "Test accuracy for BiLSTM+Glove Model is: 0.8500000238418579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84        11\n",
      "           1       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.86      0.85        20\n",
      "weighted avg       0.89      0.85      0.85        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(word_index) + 1,300,weights=[embedding_matrix],input_length=maxlen,trainable=True))\n",
    "model1.add(Dropout(0.6))\n",
    "model1.add(Bidirectional(LSTM(150,recurrent_dropout=0.6)))\n",
    "model1.add(Dropout(0.6))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model1_history = model1.fit(x_train, y_train, batch_size=batch_size, epochs=20,\n",
    "                            validation_split=0.1)\n",
    "score1, acc1 = model1.evaluate(x_test, y_test,\n",
    "                               batch_size=batch_size)\n",
    "print('Test accuracy for BiLSTM+Glove Model is:', acc1)\n",
    "y_pred1 = model1.predict(x_test)\n",
    "y_pred1 = (y_pred1 > 0.5)\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/19\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.6873 - acc: 0.5139 - val_loss: 0.6823 - val_acc: 0.6250\n",
      "Epoch 2/19\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.6836 - acc: 0.6389 - val_loss: 0.6741 - val_acc: 0.8750\n",
      "Epoch 3/19\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.6732 - acc: 0.7222 - val_loss: 0.6651 - val_acc: 1.0000\n",
      "Epoch 4/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.6580 - acc: 0.8889 - val_loss: 0.6552 - val_acc: 1.0000\n",
      "Epoch 5/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.6561 - acc: 0.7639 - val_loss: 0.6454 - val_acc: 0.8750\n",
      "Epoch 6/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.6330 - acc: 0.8333 - val_loss: 0.6345 - val_acc: 0.8750\n",
      "Epoch 7/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.6264 - acc: 0.7917 - val_loss: 0.6223 - val_acc: 0.8750\n",
      "Epoch 8/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.6150 - acc: 0.8333 - val_loss: 0.6092 - val_acc: 0.8750\n",
      "Epoch 9/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.6070 - acc: 0.8194 - val_loss: 0.5951 - val_acc: 0.8750\n",
      "Epoch 10/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.5954 - acc: 0.8056 - val_loss: 0.5801 - val_acc: 0.8750\n",
      "Epoch 11/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.5772 - acc: 0.7917 - val_loss: 0.5647 - val_acc: 0.8750\n",
      "Epoch 12/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.5574 - acc: 0.8056 - val_loss: 0.5490 - val_acc: 0.8750\n",
      "Epoch 13/19\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.5470 - acc: 0.8333 - val_loss: 0.5332 - val_acc: 0.8750\n",
      "Epoch 14/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.5250 - acc: 0.8333 - val_loss: 0.5173 - val_acc: 0.8750\n",
      "Epoch 15/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.5118 - acc: 0.8056 - val_loss: 0.5020 - val_acc: 0.8750\n",
      "Epoch 16/19\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.5121 - acc: 0.7778 - val_loss: 0.4879 - val_acc: 0.8750\n",
      "Epoch 17/19\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.4720 - acc: 0.8056 - val_loss: 0.4747 - val_acc: 0.8750\n",
      "Epoch 18/19\n",
      "72/72 [==============================] - 0s 541us/step - loss: 0.4631 - acc: 0.7917 - val_loss: 0.4628 - val_acc: 0.8750\n",
      "Epoch 19/19\n",
      "72/72 [==============================] - 0s 625us/step - loss: 0.4581 - acc: 0.8056 - val_loss: 0.4526 - val_acc: 0.8750\n",
      "20/20 [==============================] - 0s 200us/step\n",
      "Test accuracy for CNN+Dense Model is: 0.8500000238418579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84        11\n",
      "           1       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.86      0.85        20\n",
      "weighted avg       0.89      0.85      0.85        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(len(word_index) + 1,100,input_length=maxlen))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Conv1D(100,5,padding='valid',activation='relu',strides=2))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model2_history = model2.fit(x_train, y_train, batch_size=batch_size, epochs=19,\n",
    "                            validation_split=0.1)\n",
    "score2, acc2 = model2.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test accuracy for CNN+Dense Model is:', acc2)\n",
    "y_pred2 = model2.predict(x_test)\n",
    "y_pred2 = (y_pred2 > 0.5)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged_Data_Values.csv\n",
      "review_body    object\n",
      "dtype: object\n",
      "Sample size: 100\n",
      "                                         review_body\n",
      "0                Love it works awesome on my Sony A7\n",
      "1  I would not to recommend to anybody to but the...\n",
      "2  This bag has good cushioning and the insert in...\n",
      "3  While this camera seems pretty good, please be...\n",
      "4  This let me add 3 additional lens from an old ...\n"
     ]
    }
   ],
   "source": [
    "file_in = \"Tagged_Data_Values.csv\"\n",
    "df_unlabeled = pd.read_csv(file_in)\n",
    "df_unlabeled = df_unlabeled['review_body']\n",
    "df_unlabeled = df_unlabeled.dropna()\n",
    "df_unlabeled = df_unlabeled[1000:5000]\n",
    "df_unlabeled = df_unlabeled.reset_index()\n",
    "df_unlabeled = df_unlabeled.drop(columns = ['index'])\n",
    "\n",
    "print(file_in)\n",
    "print(df_unlabeled.dtypes)\n",
    "print(\"Sample size:\", len(df))\n",
    "print(df_unlabeled.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unlabeled = tok.texts_to_sequences(df_unlabeled['review_body'])\n",
    "x_unlabeled = sequence.pad_sequences(x_unlabeled, maxlen=maxlen)\n",
    "\n",
    "result1 = model1.predict(x_unlabeled)\n",
    "result2 = model2.predict(x_unlabeled)\n",
    "\n",
    "result1 = (result1 > 0.5)\n",
    "result2 = (result2 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = []\n",
    "for i in range(len(result1)):\n",
    "    if result1[i] != result2[i]:\n",
    "        difference.append(i)\n",
    "len(difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df_unlabeled.iloc[difference,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled.to_excel('combat_unlabeled.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Like many other reviewers, I must say you get what you pay for.  The battery works, and keeps my laptop charged.  Even after only having it for a few months the charge rarely lasts more than an hour and a half (in power save mode).',\n",
       " 'This was probably the best camera that I have ever purchased.  I am totally pleased with the pictures that were taken on it while on vacation.  This camera is very easy to use even for my tech challenged wife lol.  The pictures were clear and sharp',\n",
       " 'Like the case and it fits my camera body with 55-200 attached lense. However, manufacture should reconsider placement of shoulder strap.  It does not hang flat against your body and is a little awkward.  But, I am keeping it because it is light and stylish.',\n",
       " 'Wonderful fit, for what I require in a product and I think this product is worth the price and when it comes to saving, Amazon is GREAT ON A SCALE 1-10 the product rate as a 10, highly recommend, overall this is a great product.',\n",
       " 'This suction mount is extremely well built and offers smooth operation. It has a suction mark on the pump that alerts you that youre losing suction and need to repump. You can mount Super Clamps right on top of it.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head().review_body.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unlabeled = tok.texts_to_sequences(df_unlabeled['review_body'])\n",
    "len(x_unlabeled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
